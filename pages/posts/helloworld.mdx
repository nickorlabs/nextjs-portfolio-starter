---
title: Artificial Intelligence is here and everything is fine.
date: 2023/09/14
description: Artificial Intelligence 
tag: artificial intelligence, machine learning, AI, ML, AI/ML
author: John H.
--- 
import Image from 'next/image'

Its been said that our modern Artificial Intelligence (AI) and Machine Learning (ML) movements had their beginnings in human history at a 1950's Dartmouth College conference. However, the idea began much earlier. The concept of artificial intelligence is not a new one, even having been recorded in Greek Mythos; when the god Hephaestus created the brass humanoid, Talos, to protect the island of Crete. Many early civilizations have stories with visages of humanoid autonoma (artificial humans). Technology has finally started to catch up with the vision, and there has been slow and steady progress in the AI field and that has coincided with increases in the number of calculations per unit time. 

<Image 
  src="/images/HW1/talos.jpg" 
  alt="ho1" 
  width={859} 
  height={859} 
  priority 
  className="next-image" 
/> 

It’s not exactly certain how long the idea of Artificial Intelligence has been around, but what is evident is that it’s transition from a beautiful idea to a real piece of amazing technology is here and it is not going anywhere. Many people have reservations about AI. Fear mongering by folks like Elon Musk and suggestions are being made to enforce new regulations such as limiting who develops it, possesses it, who uses it and how it’s used. We also question the motivation of individuals and groups that would benefit financially, politically, and socially from these regulations.  Outlaw Research Labs feels that it is important to invite as many people as possible to take part in the discussion and decision making process surrounding AI since it will inevitably affect most people globally on some level.   

 We don’t believe that gross restriction is the answer and feel quite oppositely - there is no going back to a reality where we no longer have AI. AI Models are in the wild with readily available - including some that free and open source. 
 
Outlaw Research Labs, LLC (ORLabs) thinks the near omnipresence of AI is an inevitability and feel the only answer is  promoting the democratization of Artificial Intelligence. ORLabs recognizes the fears are valid, but that we should recognize and take steps to usher in AI responsibly, safely, and securely. We see these fears as challenges and they should be properly addressed with solutions.   

 Almost all verticals are integrating with AI technologies. Many predict that the adoption rate will continue to increase and as it increases the chances of encountering an adverse event will also increase. Many leaders in the space are increasingly recognizing that we need security around AI.  They are afraid of data leakage in all forms – Personal Health Information, Intellectual Property, Personally Identifiable Information etc., either intentionally or accidentally. Other risks include Data Poisoning where an attacker will tamper with raw data from AI/ML models and even Model Stealing which includes sensitive data that was used to train the model. There are serious consequences that could result from an adverse event.  They could include loss of revenue, fines, sanctions but as in the case of Knight Capital even catastrophic. Knight Capital lost $460 million in 45 minutes due to an attack on an algorithm that controlled their high frequency trading.  

Cybersecurity experts have identified security vulnerabilities in many popular AI models and tools, including OpenAI due to vulnerabilities due to open-source libraries, in this case redis-py. This could lead to a scenario where a cancelled request could result in data exposure of other users’ sensitive data.  In another incident OpenAI also faced an attack that involved using an exploit relating to the cache which resulted in the loss of ownership of user’s accounts that included other data such as billing information and chat history.  

As we have mentioned in other blog posts this week, we have found multiple vulnerabilities in several common tools / communities, including Hugging Face and Gradio, having worked through their Responsible Disclosure Programs with no resolution have decided it is time to share more on this.  ORLabs will continue to research and will be releasing updates and new findings to be in the next coming weeks.  Our team will continue to look at these frameworks and identifying other vulnerabilities.  We look forward to contributing to the overall security of Artificial Intelligence space.  

 

Stay tuned for more. 
